{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = '/Users/alex/downloads/chromedriver 2'\n",
    "browser = webdriver.Chrome(chromedriver)\n",
    "\n",
    "nhl_shop = 'https://shop.nhl.com/'\n",
    "browser.get(nhl_shop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html = browser.page_source\n",
    "soup = BeautifulSoup(page_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div/div[4]/div[2]/div[12]/div/div/div[2]/div/div[2]/a[2]/div\"}\n  (Session info: chrome=83.0.4103.116)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-683611b7dc35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mteam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/html/body/div[2]/div/div[4]/div[2]/div[12]/div/div/div[2]/div/div[2]/a[2]/div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[name=\"%s\"]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div/div[4]/div[2]/div[12]/div/div/div[2]/div/div[2]/a[2]/div\"}\n  (Session info: chrome=83.0.4103.116)\n"
     ]
    }
   ],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "team = []\n",
    "jersey = []\n",
    "\n",
    "\n",
    "jersey_link = soup.find_all('a', class_='dropdown-link')\n",
    "\n",
    "for i in range(len(jersey_link)):\n",
    "    team_link = jersey_link[i]['href']\n",
    "    browser.get(nhl_shop+team_link)\n",
    "    browser.find_element_by_xpath('//*[@id=\"0\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    browser.find_element_by_class_name('top-nav-item-link').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    browser.find_element_by_xpath('/html/body/div[2]/div/div[6]/div[2]/div[2]/div/div[2]/div[1]/div/div[2]/h4/a').click()\n",
    "    \n",
    "    page_html = browser.page_source\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    \n",
    "    team_name = soup.find('a', class_='breadcrumb-link').text\n",
    "    \n",
    "    img = browser.find_element_by_xpath('/html/body/div[2]/div/div[4]/div[1]/div[1]/div/div[1]/div/div[1]/img[1]')\n",
    "    src = img.get_attribute('src')\n",
    "\n",
    "    # download the image\n",
    "    jersey.append(urllib.request.urlretrieve(src, \"jersey.png\"))\n",
    "\n",
    "    team.append(team_name)\n",
    "    \n",
    "    try:\n",
    "        browser.find_element_by_xpath('/html/body/div[2]/div/div[4]/div[2]/div[12]/div/div/div[2]/div/div[2]/a[2]/div')\\\n",
    "        .click()\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        browser.back()\n",
    "        browser.find_element_by_xpath('/html/body/div[2]/div/div[6]/div[2]/div[2]/div/div[2]/div[2]/div/div[2]/h4/a')\\\n",
    "        .click()\n",
    "        time.sleep(3)\n",
    "        \n",
    "        page_html = browser.page_source\n",
    "        soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    \n",
    "    \n",
    "        team_name = soup.find('a', class_='breadcrumb-link').text\n",
    "    \n",
    "        img = browser.find_element_by_xpath('/html/body/div[2]/div/div[4]/div[1]/div[1]/div/div[1]/div/div[1]/img[1]')\n",
    "        src = img.get_attribute('src')\n",
    "\n",
    "        # download the image\n",
    "        jersey.append(urllib.request.urlretrieve(src, \"jersey.png\"))\n",
    "\n",
    "        team.append(team_name)\n",
    "        \n",
    "    browser.find_element_by_xpath('/html/body/div[2]/div/div[4]/div[2]/div[12]/div/div/div[2]/div/div[2]/a[2]/div')\\\n",
    "    .click()\n",
    "    time.sleep(3)\n",
    "        \n",
    "    team_name = soup.find('a', class_='breadcrumb-link').text\n",
    "    \n",
    "    #browser.find_element_by_class_name('thumbnail-link m-a-sm  active').click()\n",
    "    \n",
    "    img = browser.find_element_by_xpath('/html/body/div[2]/div/div[4]/div[1]/div[1]/div/div[1]/div/div[1]/img[1]')\n",
    "    src = img.get_attribute('src')\n",
    "\n",
    "        # download the image\n",
    "    jersey.append(urllib.request.urlretrieve(src, \"jersey.png\"))\n",
    "\n",
    "    team.append(team_name)\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "team = []\n",
    "jersey = []\n",
    "\n",
    "\n",
    "jersey_link = soup.find_all('a', class_='dropdown-link')\n",
    "\n",
    "for i in range(len(jersey_link))[:32]:\n",
    "    team_link = jersey_link[i]['href']\n",
    "    browser.get(nhl_shop+team_link)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    page_html = browser.page_source\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    \n",
    "    all_jersey_links = soup.find_all('a')\n",
    "\n",
    "    for i in range(len(all_jersey_links)):\n",
    "        jersey_test = all_jersey_links[i]\n",
    "\n",
    "        if 'Home Jersey' in jersey_test.text:\n",
    "            jersey_url = jersey_test['href']\n",
    "\n",
    "            browser.get(nhl_shop+jersey_url)\n",
    "            \n",
    "            page_html = browser.page_source\n",
    "            soup = BeautifulSoup(page_html, 'html.parser')\n",
    "            \n",
    "            team_name = soup.find('a', class_='breadcrumb-link').text\n",
    "    \n",
    "            img = browser.find_element_by_xpath(\n",
    "                '/html/body/div[2]/div/div[4]/div[1]/div[1]/div/div[1]/div/div[1]/img[1]')\n",
    "            src = img.get_attribute('src')\n",
    "\n",
    "            # download the image\n",
    "            jersey.append(urllib.request.urlretrieve(src, \"jersey.png\"))\n",
    "\n",
    "            team.append(team_name)\n",
    "            \n",
    "            \n",
    "\n",
    "        elif 'Away Jersey' in jersey_test.text:\n",
    "            jersey_url = jersey_test['href']\n",
    "\n",
    "            browser.get(nhl_shop+jersey_url)\n",
    "            \n",
    "            page_html = browser.page_source\n",
    "            soup = BeautifulSoup(page_html, 'html.parser')\n",
    "            \n",
    "            team_name = soup.find('a', class_='breadcrumb-link').text\n",
    "    \n",
    "            img = browser.find_element_by_xpath(\n",
    "                '/html/body/div[2]/div/div[4]/div[1]/div[1]/div/div[1]/div/div[1]/img[1]')\n",
    "            src = img.get_attribute('src')\n",
    "\n",
    "            # download the image\n",
    "            jersey.append(urllib.request.urlretrieve(src, \"jersey.png\"))\n",
    "\n",
    "            team.append(team_name)\n",
    "\n",
    "        elif 'Alternate Jersey' in jersey_test.text:\n",
    "            jersey_url = jersey_test['href']\n",
    "\n",
    "            browser.get(nhl_shop+jersey_url)\n",
    "            \n",
    "            page_html = browser.page_source\n",
    "            soup = BeautifulSoup(page_html, 'html.parser')\n",
    "            \n",
    "            team_name = soup.find('a', class_='breadcrumb-link').text\n",
    "    \n",
    "            img = browser.find_element_by_xpath(\n",
    "                '/html/body/div[2]/div/div[4]/div[1]/div[1]/div/div[1]/div/div[1]/img[1]')\n",
    "            src = img.get_attribute('src')\n",
    "\n",
    "            # download the image\n",
    "            jersey.append(urllib.request.urlretrieve(src, \"jersey.png\"))\n",
    "\n",
    "            team.append(team_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['jersey'] = jersey\n",
    "df['team'] = team\n",
    "\n",
    "df.to_csv('Jersey_Image_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
